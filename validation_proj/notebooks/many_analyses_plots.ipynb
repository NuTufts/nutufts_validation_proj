{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# many_analyses_plots\n",
    "Author: Noah Stiegler\n",
    "\n",
    "April 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for analyzing the results of many inference runs on many checkpoints on many data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results used with this script in April 2023 are located on the Tufts Cluster at: /cluster/home/nstieg01/validation_proj/slurm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import everything we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything uses numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import matplotlib for viewing confusion matrices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import from sklearn for making a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the datafiles I used are listed in full_data_files.txt. First check if the file is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the full data file list\n",
    "import os\n",
    "\n",
    "# The folder holding the .npy result files we want to run\n",
    "OUTPUT_DIR = \"/cluster/tufts/wongjiradlabnu/kferna03/mlreco/nutufts_validation_proj/validation_proj/slurm_results/\"\n",
    "\n",
    "# The text file with the names of the .npy files we want to run\n",
    "FULL_DATA_FILE_TXT=\"/cluster/tufts/wongjiradlabnu/kferna03/mlreco/nutufts_validation_proj/validation_proj/slurm_results/results_file_names.txt\"\n",
    "\n",
    "# export it to the shell's environment variables\n",
    "os.environ[\"FULL_DATA_FILE_TXT\"] = FULL_DATA_FILE_TXT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Use a notebook magic command %%bash to run some code in the shell (not in the notebook)\n",
    "# We use the environment variable we defined in the previous cell to check the location of the file list\n",
    "\n",
    "ls ${FULL_DATA_FILE_TXT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get all of the filenames from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by convention of previous scripts, the snapshot we used for the files are part of the file names\n",
    "#  e.g. analysis_data_10299_mlrecodata_bnb_nu_0540.root.npy\n",
    "#       the snapshot is 10299\n",
    "\n",
    "snapshots_from_files = []\n",
    "with open(FULL_DATA_FILE_TXT) as f:\n",
    "    files = [line.rstrip() for line in f]\n",
    "    # parse the list for unique snapshot numbers\n",
    "    for f in files:\n",
    "        # we parse the file name by splitting the name using the '_' character\n",
    "        \n",
    "        try:\n",
    "            snapshot_num = int(f.split(\"_\")[2])\n",
    "            # if the snapshot number found is not already in the list 'snapshots_from_files'\n",
    "            #  then we add it to the list using append\n",
    "            if snapshot_num not in snapshots_from_files:\n",
    "                snapshots_from_files.append(snapshot_num)\n",
    "        except:\n",
    "            # if there are any issues running the block of code under 'try:',\n",
    "            # we just move on to the enxt item in files\n",
    "            continue \n",
    "            \n",
    "# sort the snapshots\n",
    "snapshots_from_files.sort()\n",
    "print(\"number of files: \",len(files))\n",
    "print(\"snapshots: \",snapshots_from_files)\n",
    "#print(files) # uncomment this line if you want to dump the filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Confusion Matrices & Labels from a .npy saved analysis file\n",
    "# Returns cosmics, non_cosmics, labels\n",
    "def extract_cms(filepath):\n",
    "    # Open the saved file & load in data\n",
    "    with open(filepath, 'rb') as f:\n",
    "        result = np.load(f, allow_pickle=True)\n",
    "    \n",
    "    # Get cosmic, non-cosmic, and label data\n",
    "    # cosmic and non-cosmic are still arrays of confusion matrices for each event, will want to combine\n",
    "    non_cosmics = [event[\"confusion_matrices\"][\"non_cosmics\"] for event in result]\n",
    "    cosmics = [event[\"confusion_matrices\"][\"cosmics\"] for event in result]\n",
    "    labels = result[0][\"confusion_matrices\"][\"labels\"] # Labels should be the same for all, so just need labels from one\n",
    "    \n",
    "    # Combine confusion matrices from all events, and then from the non-cosmics and cosmics for all events\n",
    "    all_non_cosmics = sum(non_cosmics)\n",
    "    all_cosmics = sum(cosmics)\n",
    "    \n",
    "    # Return stuff\n",
    "    return all_cosmics, all_non_cosmics, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop over all 10 chosen snapshots, filling out this array as we see them\n",
    "snapshots = [None, None, None, None, None, None, None, None, None, None]\n",
    "\n",
    "for i, snapshot_num in enumerate(snapshots_from_files):\n",
    "    # Setup results for each snapshot\n",
    "    result = {}\n",
    "    all_cosmics = []\n",
    "    all_non_cosmics = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Loop over all files analyzed for each snapshot and extract cosmics & non-cosmics\n",
    "    for file in files:\n",
    "        # do not run this file if the snapshot number is not in the name of the file\n",
    "        if str(snapshot_num) not in file:\n",
    "            continue\n",
    "        analysis_location = OUTPUT_DIR + \"/\" + str(file)\n",
    "        cosmics, non_cosmics, labels = extract_cms(analysis_location)\n",
    "        all_cosmics.append(cosmics)\n",
    "        all_non_cosmics.append(non_cosmics)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    # Add together all individual confusion matrices from each file & put in result\n",
    "    result[\"cosmics\"] = sum(all_cosmics)\n",
    "    result[\"non_cosmics\"] = sum(all_non_cosmics)\n",
    "    result[\"total\"] = result[\"cosmics\"] + result[\"non_cosmics\"]\n",
    "    result[\"labels\"] = all_labels[0]\n",
    "    \n",
    "    # Store this snapshot's result\n",
    "    snapshots[i] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = snapshots[0][\"labels\"]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total confusion matrix for all events for a snapshot\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=snapshots[0][\"non_cosmics\"], display_labels=snapshots[0][\"labels\"])\n",
    "disp.plot()\n",
    "plt.title(\"What particle is it?\\nNon_Cosmics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the normalized version a given confusion matrix\n",
    "# True normalized means that rows add up to 100%\n",
    "def normalize_true(confusion_matrix):\n",
    "    normalized = np.zeros(confusion_matrix.shape)\n",
    "    for i, row in enumerate(confusion_matrix):\n",
    "        total = np.sum(row)\n",
    "        for j, col in enumerate(row):\n",
    "            if total != 0:\n",
    "                normalized[i, j] = col / total\n",
    "            else:\n",
    "                normalized[i, j] = 0\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the total confusion matrix for all events for a snapshot\n",
    "disp = ConfusionMatrixDisplay(normalize_true(confusion_matrix=snapshots[0][\"non_cosmics\"]), display_labels=snapshots[0][\"labels\"])\n",
    "disp.plot()\n",
    "plt.title(\"What particle is it?\\nNon_Cosmics (true normalized)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots[0][\"cosmics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots[0][\"cosmics\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stats each snapshot\n",
    "# Recall has to do with voxels which are really X. It's correctly guessed X / all which are really X\n",
    "# For cosmics\n",
    "c_proton_rec = []\n",
    "c_MIP_rec = []\n",
    "c_e_rec = []\n",
    "c_delta_rec = []\n",
    "c_michel_rec = []\n",
    "c_ghost_rec = []\n",
    "\n",
    "# Noncosmics\n",
    "nc_proton_rec = []\n",
    "nc_MIP_rec = []\n",
    "nc_e_rec = []\n",
    "nc_delta_rec = []\n",
    "nc_michel_rec = []\n",
    "nc_ghost_rec = []\n",
    "\n",
    "# Total\n",
    "t_proton_rec = []\n",
    "t_MIP_rec = []\n",
    "t_e_rec = []\n",
    "t_delta_rec = []\n",
    "t_michel_rec = []\n",
    "t_ghost_rec = []\n",
    "\n",
    "# Accuracy is correct (diagonals) divided by all voxels\n",
    "total_acc = []\n",
    "non_cosmic_acc = []\n",
    "cosmic_acc = []\n",
    "for snapshot in snapshots:\n",
    "    c_proton_rec.append(snapshot[\"cosmics\"][0][0] / sum(snapshot[\"cosmics\"][0]))\n",
    "    c_MIP_rec.append(snapshot[\"cosmics\"][1][1] / sum(snapshot[\"cosmics\"][1]))\n",
    "    c_e_rec.append(snapshot[\"cosmics\"][2][2] / sum(snapshot[\"cosmics\"][2]))\n",
    "    c_delta_rec.append(snapshot[\"cosmics\"][3][3] / sum(snapshot[\"cosmics\"][3]))\n",
    "    c_michel_rec.append(snapshot[\"cosmics\"][4][4] / sum(snapshot[\"cosmics\"][4]))\n",
    "    c_ghost_rec.append(snapshot[\"cosmics\"][5][5] / sum(snapshot[\"cosmics\"][5]))\n",
    "    \n",
    "    nc_proton_rec.append(snapshot[\"non_cosmics\"][0][0] / sum(snapshot[\"non_cosmics\"][0]))\n",
    "    nc_MIP_rec.append(snapshot[\"non_cosmics\"][1][1] / sum(snapshot[\"non_cosmics\"][1]))\n",
    "    nc_e_rec.append(snapshot[\"non_cosmics\"][2][2] / sum(snapshot[\"non_cosmics\"][2]))\n",
    "    nc_delta_rec.append(snapshot[\"non_cosmics\"][3][3] / sum(snapshot[\"non_cosmics\"][3]))\n",
    "    nc_michel_rec.append(snapshot[\"non_cosmics\"][4][4] / sum(snapshot[\"non_cosmics\"][4]))\n",
    "    nc_ghost_rec.append(snapshot[\"non_cosmics\"][5][5] / sum(snapshot[\"non_cosmics\"][5]))\n",
    "    \n",
    "    t_proton_rec.append(snapshot[\"total\"][0][0] / sum(snapshot[\"total\"][0]))\n",
    "    t_MIP_rec.append(snapshot[\"total\"][1][1] / sum(snapshot[\"total\"][1]))\n",
    "    t_e_rec.append(snapshot[\"total\"][2][2] / sum(snapshot[\"total\"][2]))\n",
    "    t_delta_rec.append(snapshot[\"total\"][3][3] / sum(snapshot[\"total\"][3]))\n",
    "    t_michel_rec.append(snapshot[\"total\"][4][4] / sum(snapshot[\"total\"][4]))\n",
    "    t_ghost_rec.append(snapshot[\"total\"][5][5] / sum(snapshot[\"total\"][5]))\n",
    "    \n",
    "    total_acc.append(sum(snapshot[\"total\"].diagonal()) / np.sum(snapshot[\"total\"]))\n",
    "    non_cosmic_acc.append(sum(snapshot[\"non_cosmics\"].diagonal()) / np.sum(snapshot[\"non_cosmics\"]))\n",
    "    cosmic_acc.append(sum(snapshot[\"cosmics\"].diagonal()) / np.sum(snapshot[\"cosmics\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_nums = snapshots_from_files\n",
    "plt.plot(snapshot_nums, total_acc, color=\"black\", linewidth=.5)\n",
    "plt.scatter(snapshot_nums, total_acc, label=\"Total Accuracy\", color='black')\n",
    "\n",
    "plt.plot(snapshot_nums, non_cosmic_acc, color=\"blue\", linewidth=.5)\n",
    "plt.scatter(snapshot_nums, non_cosmic_acc, label=\"Non-Cosmic Accuracy\", color='blue', marker=\"^\")\n",
    "\n",
    "plt.plot(snapshot_nums, cosmic_acc, color=\"red\", linewidth=.5)\n",
    "plt.scatter(snapshot_nums, cosmic_acc, label=\"Cosmic Accuracy\", color='red', marker='x')\n",
    "\n",
    "plt.title(\"Total Accuracy For Each Snapshot\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Snapshot\")\n",
    "plt.xticks(snapshot_nums, rotation=20)\n",
    "plt.legend()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all recalls for cosmics\n",
    "plt.plot(snapshot_nums, c_proton_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, c_proton_rec, label=labels[0])\n",
    "plt.plot(snapshot_nums, c_MIP_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, c_MIP_rec, label=labels[1])\n",
    "plt.plot(snapshot_nums, c_e_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, c_e_rec, label=labels[2])\n",
    "plt.plot(snapshot_nums, c_delta_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, c_delta_rec, label=labels[3])\n",
    "plt.plot(snapshot_nums, c_michel_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, c_michel_rec, label=labels[4])\n",
    "plt.plot(snapshot_nums, c_ghost_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, c_ghost_rec, label=labels[5])\n",
    "\n",
    "# Title etc.\n",
    "plt.title(\"Recall of Classes by Snapshot\\nCosmics\")\n",
    "plt.ylabel(\"Recall [True X and Predicted X / True X]\")\n",
    "plt.xlabel(\"Snapshot\")\n",
    "plt.xticks(snapshot_nums, rotation=20)\n",
    "plt.legend(loc='center left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all recalls for non-cosmics\n",
    "plt.plot(snapshot_nums, nc_proton_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, nc_proton_rec, label=labels[0])\n",
    "plt.plot(snapshot_nums, nc_MIP_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, nc_MIP_rec, label=labels[1])\n",
    "plt.plot(snapshot_nums, nc_e_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, nc_e_rec, label=labels[2])\n",
    "plt.plot(snapshot_nums, nc_delta_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, nc_delta_rec, label=labels[3])\n",
    "plt.plot(snapshot_nums, nc_michel_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, nc_michel_rec, label=labels[4])\n",
    "plt.plot(snapshot_nums, nc_ghost_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, nc_ghost_rec, label=labels[5])\n",
    "\n",
    "# Title etc.\n",
    "plt.title(\"Recall of Classes by Snapshot\\nNon-Cosmics\")\n",
    "plt.ylabel(\"Recall [True X and Predicted X / True X]\")\n",
    "plt.xlabel(\"Snapshot\")\n",
    "plt.xticks(snapshot_nums, rotation=20)\n",
    "plt.legend(loc='center left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all recalls for total\n",
    "plt.plot(snapshot_nums, t_proton_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, t_proton_rec, label=labels[0])\n",
    "plt.plot(snapshot_nums, t_MIP_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, t_MIP_rec, label=labels[1])\n",
    "plt.plot(snapshot_nums, t_e_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, t_e_rec, label=labels[2])\n",
    "plt.plot(snapshot_nums, t_delta_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, t_delta_rec, label=labels[3])\n",
    "plt.plot(snapshot_nums, t_michel_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, t_michel_rec, label=labels[4])\n",
    "plt.plot(snapshot_nums, t_ghost_rec, linewidth=0.5)\n",
    "plt.scatter(snapshot_nums, t_ghost_rec, label=labels[5])\n",
    "\n",
    "# Title etc.\n",
    "plt.title(\"Recall of Classes by Snapshot\\nTotal\")\n",
    "plt.ylabel(\"Recall [True X and Predicted X / True X]\")\n",
    "plt.xlabel(\"Snapshot\")\n",
    "plt.xticks(snapshot_nums, rotation=20)\n",
    "plt.legend(loc='center left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
